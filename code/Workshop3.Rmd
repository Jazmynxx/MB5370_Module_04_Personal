---
title: "MB5370 Module 04. Workshop 3 - Data Wrangling"
output: html_document
author: "Jazmyn Wise"
date: "18/09/2025"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Loading packages
```{r}
library(ggplot2)
library(tidyverse)
```

~BACKGROUND KNOWLEDGE~
Tibbles:
What are tibbles? Well, basically a dataframe!
They are slightly adjusted dataframes which were designed to keep up with recent advances in R. Some things that were useful in R a decade ago, now hinder users rather than help them, so tibbles are a kind of future proof data frame. 


~TIDYING DATA USING TIDYR~
Tidyr is part of the tidyverse package which we've already loaded.
There are three rules for a tidy dataset:
1. Each variable must have its own column.
2. Each observation must have its own row.
3. Each value must have its own cell.

```{r}
table1
#> # A tibble: 6 × 4
#>   country      year  cases population
#>   <chr>       <int>  <int>      <int>
#> 1 Afghanistan  1999    745   19987071
#> 2 Afghanistan  2000   2666   20595360
#> 3 Brazil       1999  37737  172006362
#> 4 Brazil       2000  80488  174504898
#> 5 China        1999 212258 1272915272
#> 6 China        2000 213766 1280428583
table2
#> # A tibble: 12 × 4
#>   country      year type           count
#>   <chr>       <int> <chr>          <int>
#> 1 Afghanistan  1999 cases            745
#> 2 Afghanistan  1999 population  19987071
#> 3 Afghanistan  2000 cases           2666
#> 4 Afghanistan  2000 population  20595360
#> 5 Brazil       1999 cases          37737
#> 6 Brazil       1999 population 172006362
#> # ... with 6 more rows
table3
#> # A tibble: 6 × 3
#>   country      year rate             
#> * <chr>       <int> <chr>            
#> 1 Afghanistan  1999 745/19987071     
#> 2 Afghanistan  2000 2666/20595360    
#> 3 Brazil       1999 37737/172006362  
#> 4 Brazil       2000 80488/174504898  
#> 5 China        1999 212258/1272915272
#> 6 China        2000 213766/1280428583
```
Only table 1 is tidy

Using the pipe function: %>% (only for tidyverse) or |>
```{r}
# Compute rate per 10,000
table1 %>% 
  mutate(rate = cases / population * 10000)
#> # A tibble: 6 × 5
#>   country      year  cases population  rate
#>   <chr>       <int>  <int>      <int> <dbl>
#> 1 Afghanistan  1999    745   19987071 0.373
#> 2 Afghanistan  2000   2666   20595360 1.29 
#> 3 Brazil       1999  37737  172006362 2.19 
#> 4 Brazil       2000  80488  174504898 5.61 
#> 5 China        1999 212258 1272915272 1.67 
#> 6 China        2000 213766 1280428583 1.67

# Compute cases per year
table1 %>% 
  count(year, wt = cases)
#> # A tibble: 2 × 2
#>    year      n
#>   <int>  <int>
#> 1  1999 250740
#> 2  2000 296920

# Visualise changes over time
library(ggplot2)
ggplot(table1, aes(year, cases)) + 
  geom_line(aes(group = country), colour = "grey50") + 
  geom_point(aes(colour = country))
```

EXCERSIE 1:
1. For each of the sample tables, describe what each observation and each column represents.
Table 1. Each observation shows a countrys cases and populations for a specific year. Each column represents the country, year, number of cases, and population.

Table 2. Each observation shows a country, year, type (cases or population), and count. Each column represents the country, year, type, and count.

Table 3. Each observation shows a country, year, and rate (cases/population). Each column represents the country, year, and rate.

2. Sketch out the processes you would use to calculate the rate for table2 and table3. You will need to perform four operations:
a. Extract the number of TB cases per country per year
b. Extract the matching population per country per year
c. Divide cases by population, and multiply by 10,000
d. Store back in the appropriate place
```{r}
table2_wide <- table2 %>%
  pivot_wider(names_from = type, values_from = count) %>% 
  mutate(rate = (cases / population) * 10000)
table2_wide
#Table 3
table3_clean <- table3 %>%
  separate(rate, into = c("cases", "population"), sep = "/", convert = TRUE) %>%
  mutate(rate = (cases / population) * 10000)
table3_clean
```

~LENGTHENING DATASETS~
pivot_longer() makes datasets “longer” by increasing the number of rows and decreasing the number of columns, solving those common problems of data values in the variable names.
facet_wrap() for if you want to group our data by year, or use it as a factor, and ggplot2 and most statistical packages cannot do this with data in columns.

Using pivot_longer():
```{r}
billboard #premade tibble we'll use for this example

billboard |> 
  pivot_longer(
    cols = starts_with("wk"), #this is the columns we want to pivot 
    names_to = "week", #this is what the new column will be called
    values_to = "rank" #this is what the new column will be called
  )
```

Closer look at pivot_longer():
```{r}
df <- tribble(
  ~id,  ~bp1, ~bp2,
   "A",  100,  120,
   "B",  140,  115,
   "C",  120,  125
)
```
So we've created a data set however, we want our new (tidy) dataset to have three variables: 
id (which already exists)
measurement (the column names) 
value (the cell values)
```{r}
df |> 
  pivot_longer(
    cols = bp1:bp2,
    names_to = "measurement",
    values_to = "value"
  ) #pivots and repeats id for each measurement
```

~WIDENING DATASETS~
When we need to widen a dataset rather than lengthen it.
Done using pivot_wider()
Allows us to handle an observation if it is scattered across multiple rows. 
```{r}
cms_patient_experience #premade tibble we'll use for this example

cms_patient_experience |> 
  distinct(measure_cd, measure_title) #shows unique values in these columns
```
Neither of these columns will make particularly great variable names: measure_cd doesn’t hint at the meaning of the variable and measure_title is a long sentence containing spaces. We’ll use measure_cd as the source for our new column names for now, but in a real analysis you might want to create your own variable names that are both short and meaningful.

pivot_wider() has the opposite interface to pivot_longer(): instead of choosing new column names, we need to provide the existing columns that define the values (values_from) and the column name (names_from):

```{r}
cms_patient_experience |> 
  pivot_wider(
    names_from = measure_cd, 
    values_from = prf_rate
  )
```
But this output still isn't quite right; we still seem to have multiple rows for each organization. That’s because, we also need to tell pivot_wider() which column or columns have values that uniquely identify each row; in this case those are the variables starting with "org":
```{r}
cms_patient_experience |> 
  pivot_wider(
    id_cols = starts_with("org"),
    names_from = measure_cd,
    values_from = prf_rate
  )
```
Yay! This is the output we were looking for.

Now, to further understand what pivot_wider does to our data:
```{r}
df <- tribble( #making a simple dataset for example
  ~id, ~measurement, ~value,
  "A",        "bp1",    100,
  "B",        "bp1",    140,
  "B",        "bp2",    115, 
  "A",        "bp2",    120,
  "A",        "bp3",    105
)

df |> 
  pivot_wider(
    names_from = measurement, #new column names
    values_from = value #new column values
  )
```
Pivot Process:
```{r}
# To start the pivoting process, pivot_wider() needs to first figure out what will go in the rows and columns. The new column names will be the unique values of measurement.
df |> 
  distinct(measurement) |> 
  pull()

#By default, the rows in the output are determined by all the variables that aren’t going into the new names or values. These are called the id_cols. Here there is only one column, but in general there can be any number.
df |> 
  select(-measurement, -value) |> 
  distinct()
#Pivot_widerthen combines these results to generate an empty data frame
df |> 
  select(-measurement, -value) |> 
  distinct() |> 
  mutate(x = NA, y = NA, z = NA)
It then fills in all the missing values using the data in the input. In this case, not every cell in the output has a corresponding value in the input as there’s no third blood pressure measurement for patient B, so that cell remains missing.
```

EXERCISE 2:
1. Why are pivot_longer() and pivot_wider() not perfectly symmetrical? Carefully consider the following example. 

(Hint: look at the variable types and think about column names) pivot_longer() has a names_ptypes argument, e.g.  names_ptypes = list(year = double()). What does it do?
```{r}

stocks <- tibble(
  year   = c(2015, 2015, 2016, 2016),
  half  = c(   1,    2,     1,    2),
  return = c(1.88, 0.59, 0.92, 0.17)
)
stocks %>% 
  pivot_wider(names_from = year, values_from = return) %>% 
  pivot_longer(`2015`:`2016`, names_to = "year", values_to = "return")

#widening then lengthening again does not return to the original data frame. Why not?
wide <- stocks %>% pivot_wider(names_from = year, values_from = return)# column names are "2015", "2016" (character labels)
long_default <- wide %>% pivot_longer(`2015`:`2016`, names_to = "year", values_to = "return")
# long_default$year is character ("2015", "2016"), not numeric
```
They're not perfectly symmetrical because when you pivot_wider, the new column names are character strings, even if they were originally numeric. So when you pivot_longer again, those column names become values in a character column, not numeric.

And the argument names_ptypes allows you to specify the desired type for the names column when pivoting longer. For example, using names_ptypes = list(year = double()) would ensure that the 'year' column is treated as numeric (double) instead of character.

2. Why does this code fail?
```{r}
table4a %>% 
  pivot_longer(c(1999, 2000), names_to = "year", values_to = "cases")

table4a #checking how the table looks

#attempting to fix it:
table4a %>% 
  pivot_longer(c("1999", "2000"), names_to = "year", values_to = "cases") #yay fixed!
```
So the original code fails because the column names in table4a are character strings ("1999", "2000"), not numeric values (1999, 2000). When using pivot_longer, you need to specify the column names as they are in the data frame, which are character strings in this case. By enclosing them in "", the code works correctly. Instead it was trying to find columns number 1999 and 2000, which do not exist.

3. Consider the sample tibble below. Do you need to make it wider or longer? What are the variables?
```{r}
preg <- tribble(
  ~pregnant, ~male, ~female,
  "yes",     NA,    10,
  "no",      20,    12
)
# make longer, male and female are a variable.

preg_long <- preg %>%
  pivot_longer(cols = c(male, female),
               names_to = "sex",
               values_to = "count")
```
Yes, we needed to make the tribble longer. The variables are pregnant, sex and count

~SEPARATING AND UNITING DATA TABLES~
In table3, we see one column (rate) that contains two variables (cases and population). To address this, we can use the separate() function which separates one column into multiple columns wherever you designate.
```{r}
table3 #checking how the table looks, rate column has two variables in it separated by "/"

table3 |> 
  separate(rate, into = c("cases", "population")) #makes two new columns, but they're characters

table3 %>% 
  separate(rate, into = c("cases", "population"), convert = TRUE) #makes two new columns, and convert = TRUE changes them to numeric
```
By default, separate() will split values wherever it sees a non-alphanumeric character (i.e. a character that isn’t a number or letter). For example, in the code above, separate() split the values of rate at the forward slash characters. If you wish to use a specific character to separate a column, you can pass the character to the sep argument of separate(). For example, we could rewrite the code above as:
table3 %>% 
  separate(rate, into = c("cases", "population"), sep = "/")
  
You can also use separate() to split a column at a specific position. For example, if you wanted to split years into century and year within century, you could do:
```{r}
table3 %>% 
  separate(year, into = c("century", "year"), sep = 2) #where sep = 2 means split after the second character
```

You can do the opposite of separate() using unite(), which combines multiple columns into a single column.

```{r}
table5 %>% 
  unite(new, century, year, sep = "") #combines century and year into a new column called new, with no space between them
```

~WORKING WITH MISSING VALUES~
1. NA (explicit absence)- presence of absent data.
2. Fixed values- missing values represented most commonly by 0
3. NaN (not a number)- result of undefined mathematical operations
4. Blank cell (implicit absence)- absence of data.

1. Explicit Values (NAs)
```{r}
treatment <- tribble(
  ~person,           ~treatment, ~response,
  "Derrick Whitmore", 1,         7,
  NA,                 2,         10,
  NA,                 3,         NA,
  "Katherine Burke",  1,         4
)

treatment |>
  fill(everything()) #fills in NAs with the value above it- "last observation carried forward". Can use argument .direction = "up" to fill in the other way
```

2. Fixed Values (missing value = 0):
You can use dplyr::coalesce() to replace NA with 0.
```{r}
x <- c(1, 4, 5, 7, NA)

coalesce(x, 0)
```

And sometimes you may have the opposite problem, where some other concrete value actually presents a missing value. I.e., from older software
You can use dplyr::na_if().
```{r}
x <- c(1, 4, 5, 7, -99)

na_if(x, -99)
```

3. NaN (not a number)
Distinguish it using is.nan()
```{r}
x <- c(NA, NaN)
x * 10
x == 1

is.na(x)
is.nan(x)
```

4. Blank Cells (implicit absence)
```{r}
stocks <- tibble(
  year  = c(2020, 2020, 2020, 2020, 2021, 2021, 2021),
  qtr   = c(   1,    2,    3,    4,    2,    3,    4), #example we'll use
  price = c(1.88, 0.59, 0.35,   NA, 0.92, 0.17, 2.66)
)
```

This dataset has 2 missing observations: the price for 2020 Q4 is NA, and the price for 2021 Q1 is missing entirely. We can use complete() to make these implicit missing values explicit:
```{r}
stocks |> 
  complete(year, qtr)

#Or when we pivot_wider(), both missing values become explicit NAs:
stocks |>
  pivot_wider(
    names_from = qtr, 
    values_from = price
  )
```

~IMPORTING DATA INTO R~
Using readr package (part of tidyverse)

For CSV files, the columns are separated by commas. Use read_csv()
```{r}
students <- read_csv("https://pos.it/r4ds-students-csv")
```

~NEXT STEPS~
Once datas in, step 1 should be to assess whether its tidy.
- Are observations in rows?
- Are variables in columns?
- Are values in cells?

+You also need to check if data is valid. Any off variables/ strange things like spelling errors.

```{r}
students #checking how the data looks
```

In favourite.food, character string N/A is not a real NA that R will recognize. We can use the na argument to address this. 
read_csv() will only recognize empty strings as NAs- we need to edit that
```{r}
students <- read_csv("https://pos.it/r4ds-students-csv", na = c("N/A", "")) #now N/A and empty strings will be read as NAs

students
```

EXERCISE 3:
1. Identify what is wrong with each of the following inline CSV files. What happens when you run the code?
```{r}
read_csv("a,b\n1,2,3\n4,5,6") #only 2 columns but 3 values
read_csv("a,b,c\n1,2\n1,2,3,4") #3 columns but 2 values in 1st row and 4 in second
read_csv("a,b\n\"1") #missing end quote
read_csv("a,b\n1,2\na,b") #letters in numeric column/ different types in columns
read_csv("a;b\n1;3") #wrong delimiter, should be comma not semicolon
```

~RATIONAL DATA~
= Collection of multiple data tables in a dataset that are related to each other
Using dplyr package (part of tidyverse).
Provides the following verbs to work with relational data:
1. Mutating joins - add new variables to one dataframe from matching observations in another
2. Filtering joins - filter observations from one data frame based on whether or not they match an observation in the other table
3. Set operations - treat observations as if they are set elements

Loading libraries:
```{r}
library(tidyverse)
library(nycflights13)
```

Loooking at the data tables:
```{r}
airlines

airports

planes

weather

flights
```
These tables have the following relationships:
flights connects to planes via a single variable, tailnum.
flights connects to airlines through the carrier variable.
flights connects to airports in two ways: via origin and dest variables.
flights connects to weather via origin (the location), and year, month, day and hour (the time).

~JOINING DATASETS~
First need to identify the keys.
A key is a variable (or set of variables) that uniquely identifies an observation in a table. I.e., tailnum uniquely identifies each plane. And year, month, day, hour, origin for weather.

Two types of keys:
1. Primary key- identifies an observation in its own table. I.e., planes$tailnum.
2. Foreign key- identifies an observation in another table. I.e., flights$tailnum.

So first step is to make sure the keys are unique, you can do this by count() the primary keys and look for entries greater than one:
```{r}
planes %>% 
  count(tailnum) %>% 
  filter(n > 1)
#no entries greater than 1, so tailnum is a valid primary key

weather %>% 
  count(year, month, day, hour, origin) %>% 
  filter(n > 1)
#combination of year, month, day, hour, origin is a valid primary key
```

Sometimes there isnt an explicit primary key, like for the flights table:
```{r}
flights %>% 
  count(year, month, day, flight) %>% 
  filter(n > 1)

flights %>% 
  count(year, month, day, tailnum) %>% 
  filter(n > 1)
#there are multiple entries for each combination, so no explicit primary key
```

When there isnt a primary key, its sometimes useful to add one with mutate() and row_number().
This is called a surrogate key.

~MUTATING JOINS~
Used for combining a pair of tables.
Matches the observations in the two tables based on one or more keys, and copies across variables from one table to the other.
mutate() adds variables to the right side of the data table.
left_join() is the most common type of mutating join, it keeps all observations in the left table, and adds matching variables from the right table.

Join types:
left_join() keeps all observations in x (we’ll see this in our first example)
right_join() keeps all observations in y
full_join() keeps all observations in x and y

```{r}
flights2 <- flights %>% 
  select(year:day, hour, origin, dest, tailnum, carrier)
#first making a subset so its easier to see the variables

flights2 %>%
  select(-origin, -dest) %>% 
  left_join(airlines, by = "carrier") #joining flights2 with airlines, using carrier as the key
#left_join() keeps all rows in the left table (flights2) and adds matching columns from the right table (airlines)
```

What this did is add the airline names to the fights 2 dataframe, based on the carrier code. It added the names to the right. 

We could have used the R base mutate() but its much more complicated and messy- so its better to use a mutating join:
```{r}
flights2 %>%
  select(-origin, -dest) %>% 
  mutate(name = airlines$name[match(carrier, airlines$carrier)]) #more messy/ complicated
```

~more info about joins in the workbook

~PIPES~
= help implement wrangling steps with less code. 
So far we've learnt 'filter', 'group_by', 'summarize', and 'mutate' and coded them separately.. Pipes allow us to use them together in a sequence.
We can use the base R pipes |>.

Using pipes to tell this story: 
  Little bunny Foo Foo
	Went hopping through the forest
	Scooping up the field mice
	And bopping them on the head
	
```{r}
little_bunny <- function() {
  "Little bunny Foo Foo"
}

hop <- function() {
  "went hopping through the forest"
}

scoop <- function(x) {
  "scooping up the field mice"
}

bop <- function(x) {
  "and bopping them on the head"
}

foo_foo <- little_bunny() %>%
  hop() %>%
  scoop() %>%
  bop()


```
